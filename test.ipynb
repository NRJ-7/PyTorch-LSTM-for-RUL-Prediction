{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaf87ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from loading_data import add_rul_1\n",
    "import plotly.express as px\n",
    "from torch.autograd import Variable\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf8a4777",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load and preprocess the FD001 dataset.\n",
    ":param cut: upper limit for target RULs\n",
    ":return: grouped data per sample\n",
    "\"\"\"\n",
    "# load data FD001.py\n",
    "# define filepath to read data\n",
    "dir_path = './CMAPSSData/'\n",
    "\n",
    "# define column names for easy indexing\n",
    "index_names = ['unit_nr', 'time_cycles']\n",
    "setting_names = ['setting_1', 'setting_2', 'setting_3']\n",
    "sensor_names = ['s_{}'.format(i) for i in range(1, 22)]\n",
    "col_names = index_names + setting_names + sensor_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a417669d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "train_data = pd.read_csv((dir_path + 'train_FD001.txt'), sep='\\s+', header=None, names=col_names)\n",
    "test_data = pd.read_csv((dir_path + 'test_FD001.txt'), sep='\\s+', header=None, names=col_names)\n",
    "y_test = pd.read_csv((dir_path + 'RUL_FD001.txt'), sep='\\s+', header=None, names=['RUL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d2ec124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop non-informative features, derived from EDA\n",
    "drop_sensors = ['s_1', 's_5', 's_10', 's_16', 's_18', 's_19']\n",
    "drop_labels = setting_names + drop_sensors\n",
    "\n",
    "train_data.drop(labels=drop_labels, axis=1, inplace=True)\n",
    "title = train_data.iloc[:, 0:2]\n",
    "data = train_data.iloc[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e90e5048",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_norm = (data - data.min()) / (data.max() - data.min())  # min-max normalization\n",
    "# data_norm = (data-data.mean())/data.std()  # standard normalization (optional)\n",
    "train_norm = pd.concat([title, data_norm], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a92a97b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_norm = add_rul_1(train_norm)\n",
    "df = train_norm.copy()\n",
    "\"\"\"\n",
    "def add_rul_1(df):\n",
    ":param df: raw data frame\n",
    ":return: data frame labeled with targets\n",
    "\"\"\"\n",
    "# Get the total number of cycles for each unit\n",
    "grouped_by_unit = df.groupby(by=\"unit_nr\")\n",
    "max_cycle = grouped_by_unit[\"time_cycles\"].max()\n",
    "\n",
    "# Merge the max cycle back into the original frame\n",
    "result_frame = df.merge(max_cycle.to_frame(name='max_cycle'), left_on='unit_nr', right_index=True)\n",
    "\n",
    "# Calculate remaining useful life for each row (piece-wise Linear)\n",
    "remaining_useful_life = result_frame[\"max_cycle\"] - result_frame[\"time_cycles\"]\n",
    "\n",
    "result_frame[\"RUL\"] = remaining_useful_life\n",
    "# drop max_cycle as it's no longer needed\n",
    "result_frame = result_frame.drop(\"max_cycle\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c83aa02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_norm = result_frame.copy()\n",
    "# as in piece-wise linear function, there is an upper limit for target RUL,\n",
    "# however, experimental results shows this goes even better without it:\n",
    "# train_norm['RUL'].clip(upper=cut, inplace=True)\n",
    "group_train = train_norm.groupby(by=\"unit_nr\")\n",
    "\n",
    "test_data.drop(labels=drop_labels, axis=1, inplace=True)\n",
    "title = test_data.iloc[:, 0:2]\n",
    "data = test_data.iloc[:, 2:]\n",
    "data_norm = (data - data.min()) / (data.max() - data.min())\n",
    "test_norm = pd.concat([title, data_norm], axis=1)\n",
    "group_test = test_norm.groupby(by=\"unit_nr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e75c2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "X, y = group_train.get_group(i).iloc[:, 2:-1], group_train.get_group(i).iloc[:, -1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7d0f1b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1837, 0.4068, 0.3098,  ..., 0.3333, 0.7132, 0.7247],\n",
       "        [0.2831, 0.4530, 0.3526,  ..., 0.3333, 0.6667, 0.7310],\n",
       "        [0.3434, 0.3695, 0.3705,  ..., 0.1667, 0.6279, 0.6214],\n",
       "        ...,\n",
       "        [0.7319, 0.6143, 0.7377,  ..., 0.8333, 0.2713, 0.2393],\n",
       "        [0.6416, 0.6828, 0.7346,  ..., 0.5000, 0.2403, 0.3249],\n",
       "        [0.7018, 0.6621, 0.7588,  ..., 0.6667, 0.2636, 0.0976]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensors = Variable(torch.Tensor(X.to_numpy()))\n",
    "X_train_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c33b446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1837, 0.4068, 0.3098,  ..., 0.3333, 0.7132, 0.7247]],\n",
       "\n",
       "        [[0.2831, 0.4530, 0.3526,  ..., 0.3333, 0.6667, 0.7310]],\n",
       "\n",
       "        [[0.3434, 0.3695, 0.3705,  ..., 0.1667, 0.6279, 0.6214]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.7319, 0.6143, 0.7377,  ..., 0.8333, 0.2713, 0.2393]],\n",
       "\n",
       "        [[0.6416, 0.6828, 0.7346,  ..., 0.5000, 0.2403, 0.3249]],\n",
       "\n",
       "        [[0.7018, 0.6621, 0.7588,  ..., 0.6667, 0.2636, 0.0976]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensors = torch.reshape(X_train_tensors, (X_train_tensors.shape[0], 1, X_train_tensors.shape[1]))\n",
    "X_train_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d07fb054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1837, 0.4068, 0.3098, 1.0000, 0.7262, 0.2424, 0.1098, 0.3690, 0.6333,\n",
       "         0.2059, 0.1996, 0.3640, 0.3333, 0.7132, 0.7247]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensors[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lstm_rul_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
